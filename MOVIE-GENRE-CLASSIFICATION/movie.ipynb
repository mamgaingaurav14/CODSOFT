{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64b235c0"
      },
      "source": [
        "# Task\n",
        "Create a machine learning model to predict movie genres from plot summaries using data from \"/content/train_data.txt\", \"/content/test_data.txt\", and \"/content/test_data_solution.txt\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bf15b0a"
      },
      "source": [
        "## Load and preprocess the training data\n",
        "\n",
        "### Subtask:\n",
        "Load the training data from \"/content/train_data.txt\" and preprocess it for model training. This may involve tasks like tokenization, removing stop words, and converting text to numerical features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1e7be9b",
        "outputId": "1512c491-0055-4efc-d5d3-3fd562bdb444"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Download stopwords if not already present\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "# Reload and parse the training data\n",
        "data = []\n",
        "with open('/content/train_data.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(' ::: ')\n",
        "        if len(parts) == 4:\n",
        "            data.append({'id': parts[0], 'title': parts[1], 'genre': parts[2], 'plot': parts[3]})\n",
        "\n",
        "train_df = pd.DataFrame(data)\n",
        "\n",
        "# Handle missing values in 'plot' column\n",
        "train_df['plot'].fillna('', inplace=True)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "train_df['plot_cleaned'] = train_df['plot'].apply(preprocess_text)\n",
        "\n",
        "# Check for empty strings in cleaned plots again\n",
        "empty_cleaned_plots = train_df[train_df['plot_cleaned'].str.strip() == '']\n",
        "print(f\"\\nNumber of empty cleaned plots after re-parsing: {len(empty_cleaned_plots)}\")\n",
        "\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limiting features for demonstration\n",
        "X_train = tfidf_vectorizer.fit_transform(train_df['plot_cleaned'])\n",
        "\n",
        "# Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_df['genre'])\n",
        "\n",
        "print(\"Preprocessing complete. Shapes of features and labels:\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-614507287.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train_df['plot'].fillna('', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of empty cleaned plots after re-parsing: 0\n",
            "Preprocessing complete. Shapes of features and labels:\n",
            "X_train shape: (54214, 5000)\n",
            "y_train shape: (54214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ce8180b"
      },
      "source": [
        "## Load and preprocess the test data\n",
        "\n",
        "### Subtask:\n",
        "Load the test data from \"/content/test_data.txt\" and preprocess it using the same techniques as the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3997e7f"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the test data, handle missing values, preprocess the plot summaries using the same function as the training data, and then transform the cleaned plots into a TF-IDF matrix using the already fitted vectorizer. Finally, print the shape of the resulting matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "490643b8",
        "outputId": "6658740a-5bd4-4054-9fda-f013920cff65"
      },
      "source": [
        "# Load and parse the test data\n",
        "test_data = []\n",
        "with open('/content/test_data.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(' ::: ')\n",
        "        if len(parts) == 3: # Test data has id, title, plot\n",
        "            test_data.append({'id': parts[0], 'title': parts[1], 'plot': parts[2]})\n",
        "\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "# Handle missing values in 'plot' column\n",
        "test_df['plot'].fillna('', inplace=True)\n",
        "\n",
        "# Apply the same preprocessing function\n",
        "test_df['plot_cleaned'] = test_df['plot'].apply(preprocess_text)\n",
        "\n",
        "# Use the fitted tfidf_vectorizer to transform the test data\n",
        "X_test = tfidf_vectorizer.transform(test_df['plot_cleaned'])\n",
        "\n",
        "# Print the shape of the resulting TF-IDF feature matrix\n",
        "print(\"Shape of TF-IDF feature matrix for test data:\", X_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-826766540.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test_df['plot'].fillna('', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of TF-IDF feature matrix for test data: (54200, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ddcd8ab"
      },
      "source": [
        "## Train a machine learning model\n",
        "\n",
        "### Subtask:\n",
        "Choose a suitable machine learning model (e.g., Naive Bayes, Logistic Regression, or Support Vector Machine) and train it on the preprocessed training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f140dc10"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the Logistic Regression model and train it on the preprocessed training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae4cd6d1",
        "outputId": "c2eaef59-66e4-4e3a-c6bb-00f90344f1fe"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000) # Increased max_iter for convergence\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Logistic Regression model trained successfully.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c023e3da"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model's performance on the preprocessed test data using appropriate metrics (e.g., accuracy, precision, recall, F1-score). Compare the model's predictions with the true genres from \"/content/test_data_solution.txt\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "431938c8"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the true genres from the solution file, preprocess them using the fitted label encoder, make predictions using the trained model on the test data, calculate evaluation metrics, and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d321d4d0",
        "outputId": "dc1961b9-34d8-4eb6-e37b-fc1f458806e5"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the true genres from the solution file\n",
        "solution_data = []\n",
        "with open('/content/test_data_solution.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(' ::: ')\n",
        "        if len(parts) == 4: # Solution data has id, title, genre, plot (similar to train but we only need id and genre)\n",
        "            solution_data.append({'id': parts[0], 'genre': parts[2]})\n",
        "\n",
        "solution_df = pd.DataFrame(solution_data)\n",
        "\n",
        "# Ensure the order of genres in solution_df matches the order of predictions from test_df\n",
        "# This is important as the solution file might not be in the same order as the test file\n",
        "# We can merge or reindex based on 'id'\n",
        "# Assuming 'test_df' is already ordered by 'id' implicitly from loading,\n",
        "# we need to ensure 'solution_df' is also ordered by 'id' or align them.\n",
        "# A safe way is to create a mapping from id to genre from solution_df and use it to get true labels\n",
        "# for the order of ids in test_df.\n",
        "\n",
        "id_to_genre = solution_df.set_index('id')['genre'].to_dict()\n",
        "true_genres_ordered = [id_to_genre[str(id)] for id in test_df['id']]\n",
        "\n",
        "\n",
        "# Preprocess the true genres using the same label_encoder fitted on the training data\n",
        "y_true = label_encoder.transform(true_genres_ordered)\n",
        "\n",
        "# Use the trained model to make predictions on the preprocessed test data (X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Print the calculated evaluation metrics\n",
        "print(\"Model Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (weighted): {precision:.4f}\")\n",
        "print(f\"Recall (weighted): {recall:.4f}\")\n",
        "print(f\"F1-score (weighted): {f1:.4f}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation Metrics:\n",
            "Accuracy: 0.5837\n",
            "Precision (weighted): 0.5618\n",
            "Recall (weighted): 0.5837\n",
            "F1-score (weighted): 0.5447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9d95494"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The training data was successfully loaded, preprocessed using TF-IDF vectorization with a maximum of 5000 features, and the genres were label encoded. The resulting feature matrix `X_train` has a shape of (54214, 5000), and the label vector `y_train` has a shape of (54214,).\n",
        "*   The test data was loaded, preprocessed using the same cleaning function, and transformed into a TF-IDF feature matrix `X_test` using the vectorizer fitted on the training data. `X_test` has a shape of (54200, 5000).\n",
        "*   A Logistic Regression model was successfully trained on the preprocessed training data (`X_train`, `y_train`).\n",
        "*   The trained model's performance on the test set was evaluated, yielding an Accuracy of 0.5837, a weighted Precision of 0.5618, a weighted Recall of 0.5837, and a weighted F1-score of 0.5447.\n",
        "*   An `UndefinedMetricWarning` during precision calculation suggests that some genres present in the test set were not predicted by the model.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The model's performance is moderate. Further investigation into class imbalance and exploration of different models or feature engineering techniques could improve metrics.\n",
        "*   Analyzing the genres that were not predicted could provide insights into the model's weaknesses and guide future model improvements or data augmentation strategies.\n"
      ]
    }
  ]
}